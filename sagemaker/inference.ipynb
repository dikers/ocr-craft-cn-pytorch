{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn-northwest-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "print(region)\n",
    "\n",
    "#role = get_execution_role()\n",
    "role = 'arn:aws-cn:iam::690704700794:role/service-role/AmazonSageMaker-ExecutionRole-20200430T123312'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demo using Sagemaker inference in BYOC mode, so first we need package our container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using AWS Deep Learning Container as our base container, you can check the available list in https://aws.amazon.com/cn/releasenotes/available-deep-learning-containers-images/\n",
    "\n",
    "Remember change the base container by the region you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container build有两种方式（二选一）\n",
    "\n",
    "*  自己构建（在中国区会较慢）\n",
    "\n",
    "*   使用现有的(推荐)\n",
    "\n",
    "### 本次任务可以使用已经封装的docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建ECR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690704700794.dkr.ecr.cn-northwest-1.amazonaws.com.cn/ocr-inference-container:latest\n",
      "{\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws-cn:ecr:cn-northwest-1:690704700794:repository/ocr-inference-container\",\n",
      "        \"registryId\": \"690704700794\",\n",
      "        \"repositoryName\": \"ocr-inference-container\",\n",
      "        \"repositoryUri\": \"690704700794.dkr.ecr.cn-northwest-1.amazonaws.com.cn/ocr-inference-container\",\n",
      "        \"createdAt\": 1596479550.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Run this cell only onece to create the repository in ECR\n",
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'ocr-inference-container'\n",
    "tag = ':latest'\n",
    "uri_suffix = 'amazonaws.com'\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    uri_suffix = 'amazonaws.com.cn'\n",
    "inference_repository_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)\n",
    "print(inference_repository_uri)\n",
    "ecr = '{}.dkr.ecr.{}.{}'.format(account_id, region, uri_suffix)\n",
    "\n",
    "!aws ecr create-repository --repository-name $ecr_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 自己构建（在中国区会较慢）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'690704700794.dkr.ecr.cn-northwest-1.amazonaws.com.cn/ocr-inference-container:latest'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
      "To see help text, you can run:\n",
      "\n",
      "  aws help\n",
      "  aws <command> help\n",
      "  aws <command> <subcommand> help\n",
      "aws: error: argument operation: Invalid choice, valid choices are:\n",
      "\n",
      "batch-check-layer-availability           | batch-delete-image                      \n",
      "batch-get-image                          | complete-layer-upload                   \n",
      "create-repository                        | delete-lifecycle-policy                 \n",
      "delete-repository                        | delete-repository-policy                \n",
      "describe-images                          | describe-repositories                   \n",
      "get-authorization-token                  | get-download-url-for-layer              \n",
      "get-lifecycle-policy                     | get-lifecycle-policy-preview            \n",
      "get-repository-policy                    | initiate-layer-upload                   \n",
      "list-images                              | put-image                               \n",
      "put-lifecycle-policy                     | set-repository-policy                   \n",
      "start-lifecycle-policy-preview           | upload-layer-part                       \n",
      "get-login                                | help                                    \n",
      "Error: Cannot perform an interactive login from a non TTY device\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region cn-northwest-1 | docker login --username AWS --password-stdin 727897471807.dkr.ecr.cn-northwest-1.amazonaws.com.cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $ecr\n",
    "\n",
    "# Create ECR repository and push docker image\n",
    "!docker build -t $ecr_repository ../recognition\n",
    "\n",
    "!docker tag {ecr_repository + tag} $inference_repository_uri\n",
    "!docker push $inference_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用现有的docker镜像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将现有镜像下载到本地，并推送到自己的ECR库中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要改下面这行命令\n",
    "!aws ecr get-login-password --region cn-north-1 | docker login --username AWS --password-stdin 346044390830.dkr.ecr.cn-north-1.amazonaws.com.cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_image = '346044390830.dkr.ecr.cn-north-1.amazonaws.com.cn/spoken-language-identification-sagemaker-inference-container:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull $exist_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $ecr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag $exist_image $inference_repository_uri\n",
    "!docker push $inference_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference（两种方式均可）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意\n",
    "\n",
    "**将如下model_uri改为在training阶段得到的模型在S3中的path，形式为s3://YOUR_BUCKET_NAME/spoken/output/tensorflow-training-x-x-x-x-x-x-x/output/model.tar.gz**， 可以在console找到该训练任务，在该训练任务的描述页面中，找到“S3 模型构件”，复制即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = inference_repository_uri\n",
    "# update model_uri to your model S3 uri\n",
    "model_uri = 'YOUR_MODEL_URI'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "推理请求的结构是发送一个json结构体，json结构体里面描述：\n",
    "\n",
    "bucket: 存放待推理音频数据的存储桶\n",
    "\n",
    "audio_uri:待推理音频数据在S3的uri，不含桶名\n",
    "\n",
    "class_count: 语音语言种类，与模型训练时强相关，即模型训练的时候提供了几种语言的种类，这儿就填几，如训练时提供了5种语言，这里就写5；\n",
    "\n",
    "**即发送推理请求前，先将待推理的音频文件上传到S3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试文件格式说明\n",
    "\n",
    "bucket为保存待推理的音频文件桶名，audio_uri为该待推理文件在S3中的uri，且不含有桶名，即只有前缀，如一个名为demo1.mp3文件上传到桶名为test的s3存储桶后（且audio目录下），\n",
    "则该文件的S3 uri为s3://test/audio/demo1.mp3, 其中test为桶名，audio/demo1.mp3即为下面audio_uri的值；\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "#s3://test_bucket/audio/demo1.mp3\n",
    "\n",
    "bucket = 'test_bucket'\n",
    "audio_uri = 'audio/demo1.mp3'\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# bucket为保存待推理的音频文件桶名，audio_uri为该待推理文件在S3中的uri，且不含有桶名，即只有前缀，如一个名为demo1.mp3文件上传到桶名为test的s3存储桶后（且audio目录下），\n",
    "# 则该文件的S3 uri为s3://test/audio/demo1.mp3, 其中test为桶名，audio/demo1.mp3即为下面audio_uri的值；\n",
    "bucket = 'YOUR_BUCKET_SOTRE_AUDIO_TO_INFERENCE'\n",
    "audio_uri = 'xxxxxxxx.mp3'\n",
    "\n",
    "\n",
    "test_data = {\n",
    "    'bucket' : bucket,\n",
    "    'audio_uri' : audio_uri,\n",
    "    'class_count' : '3'\n",
    "}\n",
    "payload = json.dumps(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Using sagemaker SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below could be modified as you want\n",
    "\n",
    "initial_instance_count = 1\n",
    "instance_type = 'ml.m5.large'\n",
    "endpoint_name= 'spl-endpoint-July'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 model\n",
    "\n",
    "from sagemaker.model import Model\n",
    "image = inference_repository_uri\n",
    "tfModel =Model(\n",
    "            model_data=model_uri, \n",
    "            role=role,\n",
    "            image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 endpoint\n",
    "\n",
    "tfModel.deploy(\n",
    "    initial_instance_count=initial_instance_count,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建推理用的 predictor\n",
    "\n",
    "new_predictor = sagemaker.predictor.RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    content_type='application/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理请求代码\n",
    "\n",
    "new_sm_response = new_predictor.predict(payload)\n",
    "\n",
    "print(json.loads(new_sm_response.decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Using boto3 SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below could be modified as you want\n",
    "\n",
    "model_name = 'spl-demo'\n",
    "endpoint_config_name='spl-endpoint-config-July'\n",
    "variant_name= 'spl-variant-1-June'\n",
    "initial_instance_count = 1\n",
    "instance_type = 'ml.m5.large'\n",
    "endpoint_name= 'spl-endpoint-July'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# create model object\n",
    "\n",
    "spl_model_demo = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': image,\n",
    "        'Mode': 'SingleModel',\n",
    "        'ModelDataUrl': model_uri,\n",
    "    },\n",
    "    ExecutionRoleArn= role, \n",
    "    EnableNetworkIsolation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create endpoint config\n",
    "\n",
    "spl_endpoint_config = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': variant_name,\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': initial_instance_count,\n",
    "            'InstanceType': instance_type\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create endpoint\n",
    "\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "待上一步创建完成后再进行下面的发送推理请求。上面创建endpoint的时间大概10分钟左右，可以在console查看状态，inservice即可使用了。\n",
    "\n",
    "推理代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "region_name='cn-northwest-1'\n",
    "profile_name='default'\n",
    "\n",
    "session = boto3.session.Session(region_name=region_name, profile_name=profile_name)\n",
    "client = session.client('sagemaker-runtime')\n",
    "\n",
    "start_time = time.time()\n",
    "spl_response=client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "        Body=payload,\n",
    "        ContentType='application/json')\n",
    "end_time = time.time()\n",
    "\n",
    "print('time cost %s s' %(end_time - start_time))\n",
    "print(json.loads(spl_response['Body'].read().decode()))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "crnn",
   "language": "python",
   "name": "crnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
